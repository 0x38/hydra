hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: /checkpoint/${env:USER}/outputs/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${job:num}_${job:id}

  # job name.
  # by default populated based on your entry point filename but can be overridden here to something else.
  #name: custom_name

  # debug launching issues, set to true to run workers in the same process.
  no_workers: false

  launcher:
    queue: slurm
    # number of concurrent jobs
    concurrent: ???
    queues:
      local:
        class: fairtask.local.LocalQueueConfig
        params:
          num_workers: 2
      slurm:
        class: fairtask_slurm.slurm.SLURMQueueConfig
        params:
          num_jobs: ${hydra.launcher.concurrent}
          num_nodes_per_job: 1
          num_workers_per_node: 1
          name: ${hydra.name}
          maxtime_mins: 4320
          partition: learnfair
          cpus_per_worker: 10
          mem_gb_per_worker: 64
          gres: 'gpu:1'
          log_directory: ${hydra.sweep.dir}/.slurm
          output: slurm-%j.out
          error: slurm-%j.err

  # python logging configuration
  logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        # relative to the job log directory
        filename: ${hydra.name}.log
    root:
      level: INFO
      handlers: [console, file]

    disable_existing_loggers: False
